{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "308c4136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.calibration import LabelEncoder\n",
    "import numpy as np\n",
    "# 1. Load the data\n",
    "df = pd.read_csv('./megablunders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc872b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "PR            22\n",
      "PAR           22\n",
      "ROS           22\n",
      "FRAG          20\n",
      "MM            20\n",
      "DM            19\n",
      "CASE          19\n",
      "NONE          19\n",
      "AGREE         17\n",
      "AGREEERROR     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after dropping:\n",
      "error\n",
      "PR       22\n",
      "PAR      22\n",
      "ROS      22\n",
      "FRAG     20\n",
      "MM       20\n",
      "DM       19\n",
      "CASE     19\n",
      "NONE     19\n",
      "AGREE    17\n",
      "Name: count, dtype: int64\n",
      "error\n",
      "PR       22\n",
      "PAR      22\n",
      "ROS      22\n",
      "FRAG     20\n",
      "MM       20\n",
      "DM       19\n",
      "CASE     19\n",
      "NONE     19\n",
      "AGREE    17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# look at class imbalances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the count for each label\n",
    "print(df[\"error\"].value_counts())\n",
    "\n",
    "df_filtered = df[df[\"error\"] != \"AGREEERROR\"]\n",
    "\n",
    "# Verify the class has been removed\n",
    "print(\"\\nClass distribution after dropping:\")\n",
    "print(df_filtered[\"error\"].value_counts())\n",
    "\n",
    "# Update your DataFrame\n",
    "df = df_filtered\n",
    "\n",
    "\n",
    "print(df[\"error\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e261f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lable encoder to encode the error\n",
    "label_encoder = LabelEncoder()\n",
    "df['error'] = label_encoder.fit_transform(df['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0374c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  vectorize the text \n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "st = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e2ea997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list of strings before encoding\n",
    "sentences = df[\"original_sentence\"].tolist()\n",
    "embeddings = st.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37ee44e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"error\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19a7078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By dropping a game to the pathetic Tampa Bay D...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Although, if history is any indication, the te...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Sox almost never go down uneventfully, whi...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Because of the accumulated bad karma that hang...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The team not only has squandered huge leads bu...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   original_sentence  error\n",
       "0  By dropping a game to the pathetic Tampa Bay D...      2\n",
       "1  Although, if history is any indication, the te...      3\n",
       "2  The Sox almost never go down uneventfully, whi...      7\n",
       "3  Because of the accumulated bad karma that hang...      0\n",
       "4  The team not only has squandered huge leads bu...      6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4f67f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['error'], test_size=0.1, random_state=42, stratify=df[\"error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbb05573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordNet loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/felixstuart/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/felixstuart/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/felixstuart/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Download the necessary NLTK data first\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Check if the data was downloaded successfully\n",
    "try:\n",
    "    from nltk.corpus import wordnet\n",
    "    print(\"WordNet loaded successfully\")\n",
    "except:\n",
    "    print(\"WordNet loading failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3972d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nlaug to swap synonms \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de22ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixstuart/Documents/School/Clubs/Programming Club/Potential Projects/ML Megablunders/.venv/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [19:24:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# try xgboost\n",
    "from sklearn.utils import compute_class_weight\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert class weights to sample weights\n",
    "# Create a dictionary mapping class labels to weights\n",
    "\n",
    "unique_classes = np.unique(y_train)\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=unique_classes,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(unique_classes, weights))\n",
    "\n",
    "# Map each sample to its appropriate weight\n",
    "sample_weights = np.array([class_weight_dict[cls] for cls in y_train])\n",
    "\n",
    "# Fit the XGBoost model with sample weights\n",
    "xboost = xgb.XGBClassifier(n_estimators=5000,\n",
    "                           learning_rate=0.1,\n",
    "                           random_state=42,\n",
    "                        #    reg_alpha=0.7,\n",
    "                        #    reg_lambda=1,\n",
    "                        #    max_depth=3,\n",
    "                           scale_pos_weight=sample_weights,\n",
    "                           )\n",
    "\n",
    "\n",
    "xboost.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xboost.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"XGBoost Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
